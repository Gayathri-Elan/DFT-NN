{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad92dd63-832c-4155-95db-9956c8f503ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Neural Network Implementation of Discrete Fourier Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d52175-eea2-437a-9fd2-d7e352d5f805",
   "metadata": {},
   "source": [
    "## Importing Necessary Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7700627-1fd6-45aa-a7df-d821b61bb9f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f80ccf-f0c8-49ab-9cec-dd7425639c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dft(x):\n",
    "    return torch.fft.fft(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbe48ca-ede9-40ca-a5b1-20fe826c1caa",
   "metadata": {},
   "source": [
    "## Generation of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f76f6a92-30fd-4ef5-adf1-f75aaad1563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42) #seed used for simulation replication\n",
    "data_size = 500\n",
    "N = 10 #fixed_length of DFT\n",
    "data_input = np.random.uniform(low=-20, high=20, size = (data_size, N)) #Generate input data\n",
    "data_output = np.zeros((data_size, N), dtype = np.complex64)\n",
    "\n",
    "# Calculate respective output data using built-in function\n",
    "for i in range(data_size):\n",
    "    data_output[i] = dft(torch.tensor(data_input[i]))\n",
    "\n",
    "data_output_real = data_output.real\n",
    "data_output_imag = data_output.imag\n",
    "\n",
    "data_output_nn = np.hstack((data_output_real, data_output_imag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cce8c9-a063-4aa0-8f1a-58664b742937",
   "metadata": {},
   "source": [
    "<span style =\"font-family:cursive; font-size: 90%\">\n",
    "1. Output of NN is flattened by concatenating real part of DFT with imaginary part of DFT, that is, for each N-length input, output is 2N-length. <br/>\n",
    "2. Each row of data_output_nn now corresponds to DFT of each row of data_input, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7be04bd-7f3a-47fe-8520-c6b1e0cf0c23",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e7e89db-8ae5-46a1-9074-4157f566139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_nn(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(linear_nn,self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(input_size, output_size))\n",
    "        \n",
    "    #Forward propagation\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96514b25-d833-45b7-97f3-50f21d5b9709",
   "metadata": {},
   "source": [
    "<span style =\"font-family:cursive; font-size: 90%\">\n",
    "With prior knowledge that DFT is a linear transformation, we train a linear NN to model it\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "221d1878-36c2-4ff7-b15b-3119b135f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = N\n",
    "output_size = 2*N\n",
    "linear_model = linear_nn(input_size, output_size)\n",
    "\n",
    "#80% datasets are used for training, 20% for testing\n",
    "train_size = int(0.8 * data_size)\n",
    "\n",
    "#Mean-Squared Error loss function\n",
    "loss_fcn = nn.MSELoss()\n",
    "learning_rate = 0.01     #Hyper-parameter\n",
    "\n",
    "#Stochastic Gradient Descent Alogrithm optimizer\n",
    "optimizer = optim.SGD(linear_model.parameters(), lr = learning_rate)\n",
    "\n",
    "training_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d30518bc-4a5a-4636-a1f7-3b11edd85a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_tensor = torch.FloatTensor(data_input)\n",
    "data_output_tensor = torch.FloatTensor(data_output_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d22a4f-2b12-4878-8a90-d3dd31cbee56",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af851111-d553-450e-a0df-a75abb81f3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Error: 0.0001265338903366542\n",
      "Epoch: 20, Training Error: 5.1647478483468274e-08\n",
      "Epoch: 30, Training Error: 3.886883678902876e-11\n",
      "Epoch: 40, Training Error: 1.4894964961409927e-11\n",
      "Epoch: 50, Training Error: 1.5118938454699095e-11\n",
      "Epoch: 60, Training Error: 1.494217555350792e-11\n",
      "Epoch: 70, Training Error: 1.4687149466996278e-11\n",
      "Epoch: 80, Training Error: 1.4489299308972914e-11\n",
      "Epoch: 90, Training Error: 1.5073247410435016e-11\n",
      "Epoch: 100, Training Error: 1.4178896635356347e-11\n",
      "Epoch: 110, Training Error: 1.4703148044242256e-11\n",
      "Epoch: 120, Training Error: 1.635480071249945e-11\n",
      "Epoch: 130, Training Error: 1.471631689718613e-11\n",
      "Epoch: 140, Training Error: 1.479529255132752e-11\n",
      "Epoch: 150, Training Error: 1.511641578892057e-11\n",
      "Epoch: 160, Training Error: 1.4938458511100545e-11\n",
      "Epoch: 170, Training Error: 1.440388679749098e-11\n",
      "Epoch: 180, Training Error: 1.4682216259833193e-11\n",
      "Epoch: 190, Training Error: 1.4819112893185368e-11\n",
      "Epoch: 200, Training Error: 1.511624951242279e-11\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "for epoch in range(n_epochs):\n",
    "    linear_model.train()   #Model is set to be in training mode\n",
    "    training_error = 0\n",
    "    \n",
    "    for i in range(train_size):\n",
    "        predicted_output = linear_model(data_input_tensor[i])\n",
    "        \n",
    "        #MSE error between prediction from nn and expected output\n",
    "        loss = loss_fcn(predicted_output, data_output_tensor[i])\n",
    "        training_error = training_error + loss.item()\n",
    "        \n",
    "        #Backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    #Average of individual losses over training size\n",
    "    training_error = training_error/train_size\n",
    "    training_loss.append(training_error)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch: {epoch + 1}, Training Error: {training_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e91c1f-ae45-49de-8a48-e6d4e396f2ec",
   "metadata": {},
   "source": [
    "## Plotting Training Error vs Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cec0181-31fb-4b04-a1d3-6f6bcc55f7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training Error over Epochs')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_loss)\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Training Error\")\n",
    "plt.title(\"Training Error over Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78b384ce-65b5-4187-84b2-598b0bbb9c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linear_nn(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=10, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed53c73e-781b-4167-b33a-bbe19bb0d111",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7200042-ba53-4f66-a550-7a3350c68b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: 1.5028851427234535e-11\n"
     ]
    }
   ],
   "source": [
    "test_input = data_input_tensor[train_size + 1 : ]\n",
    "test_output = data_output_tensor[train_size + 1 : ]\n",
    "predicted_output = linear_model(test_input)\n",
    "loss = loss_fcn(predicted_output,test_output)\n",
    "\n",
    "test_error = loss.item()\n",
    "print(f\"Test Error: {test_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a496b-c7bb-4fcc-8e7f-623d547aba39",
   "metadata": {},
   "source": [
    "<span style =\"font-family:cursive; font-size: 90%\">\n",
    "Significantly low test error, the trained NN can be used as an approximate model for the required transformation\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5e4e73-a0cc-45a0-88da-86dd54c2d9f8",
   "metadata": {},
   "source": [
    "## Verifying that weights give DFT Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26566483-fb11-4aad-b983-49bb8add4c70",
   "metadata": {},
   "source": [
    "<span style =\"font-family:cursive; font-size: 90%\">\n",
    "Since the model is linear, the trained weights essentially give us the DFT matrix for given length N.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f65590f4-ad98-43d9-b396-f4b18f147539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000-1.2408e-36j,  1.0000+3.4828e-08j,  1.0000-2.4723e-08j,\n",
       "          1.0000+2.1440e-09j,  1.0000-1.4274e-07j,  1.0000-2.7580e-36j,\n",
       "          1.0000-1.1593e-07j,  1.0000-7.2956e-08j,  1.0000+9.4580e-09j,\n",
       "          1.0000-1.9895e-07j],\n",
       "        [ 1.0000+1.6856e-37j,  0.8090-5.8779e-01j,  0.3090-9.5106e-01j,\n",
       "         -0.3090-9.5106e-01j, -0.8090-5.8779e-01j, -1.0000+3.7466e-37j,\n",
       "         -0.8090+5.8779e-01j, -0.3090+9.5106e-01j,  0.3090+9.5106e-01j,\n",
       "          0.8090+5.8779e-01j],\n",
       "        [ 1.0000+3.4102e-37j,  0.3090-9.5106e-01j, -0.8090-5.8779e-01j,\n",
       "         -0.8090+5.8779e-01j,  0.3090+9.5106e-01j,  1.0000+7.5799e-37j,\n",
       "          0.3090-9.5106e-01j, -0.8090-5.8779e-01j, -0.8090+5.8779e-01j,\n",
       "          0.3090+9.5106e-01j],\n",
       "        [ 1.0000-2.4841e-37j, -0.3090-9.5106e-01j, -0.8090+5.8779e-01j,\n",
       "          0.8090+5.8779e-01j,  0.3090-9.5106e-01j, -1.0000-5.5215e-37j,\n",
       "          0.3090+9.5106e-01j,  0.8090-5.8779e-01j, -0.8090-5.8779e-01j,\n",
       "         -0.3090+9.5106e-01j],\n",
       "        [ 1.0000+4.7283e-37j, -0.8090-5.8779e-01j,  0.3090+9.5106e-01j,\n",
       "          0.3090-9.5106e-01j, -0.8090+5.8779e-01j,  1.0000+1.0510e-36j,\n",
       "         -0.8090-5.8779e-01j,  0.3090+9.5106e-01j,  0.3090-9.5106e-01j,\n",
       "         -0.8090+5.8779e-01j],\n",
       "        [ 1.0000-2.8252e-37j, -1.0000+7.5535e-08j,  1.0000-8.0050e-08j,\n",
       "         -1.0000+3.3684e-08j,  1.0000-7.2883e-08j, -1.0000-6.2796e-37j,\n",
       "          1.0000+1.5035e-07j, -1.0000+5.6284e-08j,  1.0000+2.6290e-08j,\n",
       "         -1.0000-1.7526e-08j],\n",
       "        [ 1.0000+3.8107e-37j, -0.8090+5.8779e-01j,  0.3090-9.5106e-01j,\n",
       "          0.3090+9.5106e-01j, -0.8090-5.8779e-01j,  1.0000+8.4700e-37j,\n",
       "         -0.8090+5.8779e-01j,  0.3090-9.5106e-01j,  0.3090+9.5106e-01j,\n",
       "         -0.8090-5.8779e-01j],\n",
       "        [ 1.0000-4.2021e-37j, -0.3090+9.5106e-01j, -0.8090-5.8779e-01j,\n",
       "          0.8090-5.8779e-01j,  0.3090+9.5106e-01j, -1.0000-9.3401e-37j,\n",
       "          0.3090-9.5106e-01j,  0.8090+5.8779e-01j, -0.8090+5.8779e-01j,\n",
       "         -0.3090-9.5106e-01j],\n",
       "        [ 1.0000-1.2380e-36j,  0.3090+9.5106e-01j, -0.8090+5.8779e-01j,\n",
       "         -0.8090-5.8779e-01j,  0.3090-9.5106e-01j,  1.0000-2.7518e-36j,\n",
       "          0.3090+9.5106e-01j, -0.8090+5.8779e-01j, -0.8090-5.8779e-01j,\n",
       "          0.3090-9.5106e-01j],\n",
       "        [ 1.0000+6.1130e-38j,  0.8090+5.8779e-01j,  0.3090+9.5106e-01j,\n",
       "         -0.3090+9.5106e-01j, -0.8090+5.8779e-01j, -1.0000+1.3587e-37j,\n",
       "         -0.8090-5.8779e-01j, -0.3090-9.5106e-01j,  0.3090-9.5106e-01j,\n",
       "          0.8090-5.8779e-01j]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = torch.transpose(linear_model.layers[0].weight, 0, 1)\n",
    "DFT_matrix = weight[:,0:N] + weight[:,N:2*N]*1j\n",
    "DFT_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713a3522-41a0-4cc5-91ea-fe0d9376d379",
   "metadata": {},
   "source": [
    "## Calculating DFT using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1bc89bc-6b1d-44db-9691-abd32b5ae87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_DFT(x):\n",
    "    dft_concat = linear_model(torch.FloatTensor(x)).detach().numpy()\n",
    "    return dft_concat[0:N] + dft_concat[N:2*N]*1j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19c897d-b9d2-4252-93e6-9151e2393a3d",
   "metadata": {},
   "source": [
    "<span style =\"font-family:cursive; font-size: 90%\">\n",
    "calculate_DFT uses trained NN implementation to calculate DFT of a fixed length input data\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36a0302-0871-4645-9ea0-cff7b55fae7e",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e45ace06-cfa5-4881-9cbb-2e2c4608900a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55.000008+7.2632335e-36j, -4.999997+1.5388421e+01j,\n",
       "       -4.999999+6.8819094e+00j, -4.999999+3.6327128e+00j,\n",
       "       -5.000003+1.6245978e+00j, -5.000005+1.6144037e-35j,\n",
       "       -4.999999-1.6245979e+00j, -4.999996-3.6327105e+00j,\n",
       "       -5.000001-6.8819079e+00j, -4.999999-1.5388421e+01j],\n",
       "      dtype=complex64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft_input = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "dft_output = calculate_DFT(dft_input)\n",
    "dft_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
